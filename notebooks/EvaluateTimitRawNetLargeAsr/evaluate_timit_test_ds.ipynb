{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation of Timit on RawNet trained on Large ASR"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch.utils import data\r\n",
    "\r\n",
    "import torchaudio\r\n",
    "\r\n",
    "import csv\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "import glob\r\n",
    "from pathlib import Path\r\n",
    "\r\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "CURRENT_WORKING_DIRECTORY = \"W:/SpeakerRecognitionResearch/\"\r\n",
    "\r\n",
    "TIMIT_DATASET_DIRECTORY = \"S:/timit/data/\"\r\n",
    "TIMIT_LABELS_FILE = \"notebooks/EvaluateTimitRawNetLargeAsr/SincNetDatasetSplits/TIMIT_labels.npy\"\r\n",
    "TIMIT_TEST_LIST_FILE = \"notebooks/EvaluateTimitRawNetLargeAsr/SincNetDatasetSplits/TIMIT_test.scp\"\r\n",
    "\r\n",
    "# To avoid file location related errors, we make sure \"SpeakerRecognitionResearch\" root folder is the current working directory.\r\n",
    "os.chdir(CURRENT_WORKING_DIRECTORY)\r\n",
    "os.getcwd()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'W:\\\\SpeakerRecognitionResearch'"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "# The lists provided in SincNet have the paths in lowercase while the paths in the dataset are capital case.\r\n",
    "# We mitigate this by converting the list into higher case\r\n",
    "\r\n",
    "wav_path_list = []\r\n",
    "with open(TIMIT_TEST_LIST_FILE) as f:\r\n",
    "    for line in f.readlines():\r\n",
    "        wav_path_list.append(line.strip())\r\n",
    "\r\n",
    "for i in range(len(wav_path_list)):\r\n",
    "    wav_path_list[i] = wav_path_list[i].upper()\r\n",
    "\r\n",
    "print(\"Total test wavs:\", len(wav_path_list))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total test wavs: 1386\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "path_to_spk_dict = np.load(TIMIT_LABELS_FILE, allow_pickle=True).item()\r\n",
    "type(path_to_spk_dict)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "all_speakers = [path_to_spk_dict[path.lower()] for path in wav_path_list]\r\n",
    "len(all_speakers)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1386"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "# Device\r\n",
    "\r\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
    "print(\"Using {}.\".format(device))\r\n",
    "if device==\"cuda\": print(torch.cuda.get_device_name(0))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cuda.\n",
      "NVIDIA GeForce RTX 3070 Ti\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Loading the Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "# If sample_rate = 16K and number_of_samples = 32000, then each tensor will be equivalent to 2 seconds of data\r\n",
    "SAMPLE_RATE = 16000\r\n",
    "NUMBER_OF_SAMPLES = 32000\r\n",
    "\r\n",
    "# Bangla ASR Dataset has around half of second of silence in the beginning\r\n",
    "# This constant will be used to cut samples from the left of the audio\r\n",
    "TRIM_AMOUNT_TIME = 0.3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "# Using default parameter values used in the VoxCeleb Dataset\r\n",
    "\r\n",
    "SAMPLE_RATE = 16000\r\n",
    "NUMBER_OF_SAMPLES = 32000"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "class TimitDataset(data.Dataset):\r\n",
    "    def __init__(self, dataset_dir, wav_path_list, path_to_spk_dict, target_sample_rate, target_num_samples, trim_amount_time, device, is_evalset=False):\r\n",
    "\r\n",
    "        # wav_list will have a list of stems that will be included in this dataset\r\n",
    "\r\n",
    "        self.dataset_dir = dataset_dir\r\n",
    "        self.path_to_spk_dict = path_to_spk_dict\r\n",
    "        self.wav_path_list = wav_path_list\r\n",
    "        self.target_sample_rate = target_sample_rate\r\n",
    "        self.target_num_samples = target_num_samples\r\n",
    "        self.trim_amount_time = trim_amount_time\r\n",
    "        self.device = device\r\n",
    "        self.is_evalset=is_evalset\r\n",
    "\r\n",
    "    def _resample_to_target_sr(self, signal, sample_rate):\r\n",
    "        if sample_rate != self.target_sample_rate:\r\n",
    "            resampler = torchaudio.transforms.Resample(sample_rate, self.target_sample_rate)\r\n",
    "            signal = resampler(signal)\r\n",
    "        return signal\r\n",
    "\r\n",
    "    def _mix_down_to_mono(self, signal):\r\n",
    "        if signal.shape[0] > 1:\r\n",
    "            signal = torch.mean(signal, dim=0, keepdim=True)\r\n",
    "        return signal\r\n",
    "\r\n",
    "    def _trim(self, signal):\r\n",
    "        total_samples = signal.shape[-1]\r\n",
    "\r\n",
    "        # We cut a fixed amount on the left side if the signal is big enough\r\n",
    "        trim_samples_amount = int(self.target_sample_rate * self.trim_amount_time)\r\n",
    "\r\n",
    "        if total_samples >= trim_samples_amount + self.target_num_samples:\r\n",
    "            signal = signal[: , trim_samples_amount:]\r\n",
    "            total_samples = signal.shape[-1]\r\n",
    "\r\n",
    "        # We cut from the right side if the signal is too big\r\n",
    "        if total_samples > self.target_num_samples:\r\n",
    "            signal = signal[:, :self.target_num_samples]\r\n",
    "        \r\n",
    "        # We add zero padding on the right if signal is too small\r\n",
    "        if total_samples < self.target_num_samples:\r\n",
    "            num_missing_samples = self.target_num_samples - total_samples\r\n",
    "            last_dim_padding = (0, num_missing_samples)\r\n",
    "            signal = torch.nn.functional.pad(signal, last_dim_padding)\r\n",
    "            \r\n",
    "        return signal\r\n",
    "\r\n",
    "    def _normalize_like_sincnet(self, signal):\r\n",
    "        return signal/torch.max(torch.abs(signal))\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.wav_path_list)\r\n",
    "\r\n",
    "    def __getitem__(self, index):\r\n",
    "        wav_path = self.wav_path_list[index]\r\n",
    "        label_index = self.path_to_spk_dict[wav_path.lower()]\r\n",
    "\r\n",
    "        signal, sample_rate = torchaudio.load( self.dataset_dir + wav_path)\r\n",
    "\r\n",
    "        # moving to CPU/CUDA is now done in the training phase\r\n",
    "        # signal = signal.to(self.device)\r\n",
    "\r\n",
    "        signal = self._resample_to_target_sr(signal, sample_rate)\r\n",
    "        signal = self._mix_down_to_mono(signal)\r\n",
    "\r\n",
    "        signal =  self._trim(signal)\r\n",
    "        signal = self._normalize_like_sincnet(signal)\r\n",
    "\r\n",
    "        # signal = signal.squeeze(0)\r\n",
    "\r\n",
    "        if self.is_evalset:\r\n",
    "            return signal, label_index, wav_path\r\n",
    "        else:\r\n",
    "            return signal, label_index\r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "timit_dataset = TimitDataset(\r\n",
    "    dataset_dir=TIMIT_DATASET_DIRECTORY,\r\n",
    "    wav_path_list=wav_path_list,\r\n",
    "    path_to_spk_dict=path_to_spk_dict,\r\n",
    "    target_sample_rate=SAMPLE_RATE,\r\n",
    "    target_num_samples=NUMBER_OF_SAMPLES,\r\n",
    "    trim_amount_time=TRIM_AMOUNT_TIME,\r\n",
    "    device=device,\r\n",
    "    is_evalset=True\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "timit_dataset[100]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[ 0.0054, -0.0214,  0.0404,  ...,  0.0077, -0.0152,  0.0006]]),\n",
       " 33,\n",
       " 'TRAIN/DR1/MTJS0/SI1822.WAV')"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RawNet2 Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "from torch import nn\r\n",
    "from torchsummary import summary\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import math\r\n",
    "\r\n",
    "import torch.nn.functional as F\r\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "class FRM(nn.Module):\r\n",
    "    def __init__(self, nb_dim, do_add = True, do_mul = True):\r\n",
    "        super(FRM, self).__init__()\r\n",
    "        self.fc = nn.Linear(nb_dim, nb_dim)\r\n",
    "        self.sig = nn.Sigmoid()\r\n",
    "        self.do_add = do_add\r\n",
    "        self.do_mul = do_mul\r\n",
    "    def forward(self, x):\r\n",
    "        y = F.adaptive_avg_pool1d(x, 1).view(x.size(0), -1)\r\n",
    "        \r\n",
    "        y = self.sig(self.fc(y)).view(x.size(0), x.size(1), -1)\r\n",
    "\r\n",
    "        if self.do_mul: x = x * y\r\n",
    "        if self.do_add: x = x + y\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "class Residual_block_wFRM(nn.Module):\r\n",
    "    def __init__(self, nb_filts, first = False):\r\n",
    "        super(Residual_block_wFRM, self).__init__()\r\n",
    "        self.first = first\r\n",
    "        if not self.first:\r\n",
    "            self.bn1 = nn.BatchNorm1d(num_features = nb_filts[0])\r\n",
    "        self.lrelu = nn.LeakyReLU()\r\n",
    "        self.lrelu_keras = nn.LeakyReLU(negative_slope=0.3)\r\n",
    "        \r\n",
    "        self.conv1 = nn.Conv1d(in_channels = nb_filts[0],\r\n",
    "            out_channels = nb_filts[1],\r\n",
    "            kernel_size = 3,\r\n",
    "            padding = 1,\r\n",
    "            stride = 1)\r\n",
    "        self.bn2 = nn.BatchNorm1d(num_features = nb_filts[1])\r\n",
    "        self.conv2 = nn.Conv1d(in_channels = nb_filts[1],\r\n",
    "            out_channels = nb_filts[1],\r\n",
    "            padding = 1,\r\n",
    "            kernel_size = 3,\r\n",
    "            stride = 1)\r\n",
    "        \r\n",
    "        if nb_filts[0] != nb_filts[1]:\r\n",
    "            self.downsample = True\r\n",
    "            self.conv_downsample = nn.Conv1d(in_channels = nb_filts[0],\r\n",
    "                out_channels = nb_filts[1],\r\n",
    "                padding = 0,\r\n",
    "                kernel_size = 1,\r\n",
    "                stride = 1)\r\n",
    "            \r\n",
    "        else:\r\n",
    "            self.downsample = False\r\n",
    "        self.mp = nn.MaxPool1d(3)\r\n",
    "        self.frm = FRM(\r\n",
    "            nb_dim = nb_filts[1],\r\n",
    "            do_add = True,\r\n",
    "            do_mul = True)\r\n",
    "        \r\n",
    "    def forward(self, x):\r\n",
    "        identity = x\r\n",
    "        if not self.first:\r\n",
    "            out = self.bn1(x)\r\n",
    "            out = self.lrelu_keras(out)\r\n",
    "        else:\r\n",
    "            out = x\r\n",
    "            \r\n",
    "        out = self.conv1(out)\r\n",
    "        out = self.bn2(out)\r\n",
    "        out = self.lrelu_keras(out)\r\n",
    "        out = self.conv2(out)\r\n",
    "        \r\n",
    "        if self.downsample:\r\n",
    "            identity = self.conv_downsample(identity)\r\n",
    "            \r\n",
    "        out += identity\r\n",
    "        out = self.mp(out)\r\n",
    "        out = self.frm(out)\r\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "class LayerNorm(nn.Module):\r\n",
    "\r\n",
    "    def __init__(self, features, eps=1e-6):\r\n",
    "        super(LayerNorm,self).__init__()\r\n",
    "        self.gamma = nn.Parameter(torch.ones(features))\r\n",
    "        self.beta = nn.Parameter(torch.zeros(features))\r\n",
    "        self.eps = eps\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        mean = x.mean(-1, keepdim=True)\r\n",
    "        std = x.std(-1, keepdim=True)\r\n",
    "        return self.gamma * (x - mean) / (std + self.eps) + self.beta"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "class SincConv_fast(nn.Module):\r\n",
    "    \"\"\"Sinc-based convolution\r\n",
    "    Parameters\r\n",
    "    ----------\r\n",
    "    in_channels : `int`\r\n",
    "        Number of input channels. Must be 1.\r\n",
    "    out_channels : `int`\r\n",
    "        Number of filters.\r\n",
    "    kernel_size : `int`\r\n",
    "        Filter length.\r\n",
    "    sample_rate : `int`, optional\r\n",
    "        Sample rate. Defaults to 16000.\r\n",
    "    Usage\r\n",
    "    -----\r\n",
    "    See `torch.nn.Conv1d`\r\n",
    "    Reference\r\n",
    "    ---------\r\n",
    "    Mirco Ravanelli, Yoshua Bengio,\r\n",
    "    \"Speaker Recognition from raw waveform with SincNet\".\r\n",
    "    https://arxiv.org/abs/1808.00158\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    @staticmethod\r\n",
    "    def to_mel(hz):\r\n",
    "        return 2595 * np.log10(1 + hz / 700)\r\n",
    "\r\n",
    "    @staticmethod\r\n",
    "    def to_hz(mel):\r\n",
    "        return 700 * (10 ** (mel / 2595) - 1)\r\n",
    "\r\n",
    "    def __init__(self, out_channels, kernel_size, sample_rate=16000, in_channels=1,\r\n",
    "                 stride=1, padding=0, dilation=1, bias=False, groups=1, min_low_hz=50, min_band_hz=50):\r\n",
    "\r\n",
    "        super(SincConv_fast,self).__init__()\r\n",
    "\r\n",
    "        if in_channels != 1:\r\n",
    "            #msg = (f'SincConv only support one input channel '\r\n",
    "            #       f'(here, in_channels = {in_channels:d}).')\r\n",
    "            msg = \"SincConv only support one input channel (here, in_channels = {%i})\" % (in_channels)\r\n",
    "            raise ValueError(msg)\r\n",
    "\r\n",
    "        self.out_channels = out_channels\r\n",
    "        self.kernel_size = kernel_size\r\n",
    "        \r\n",
    "        # Forcing the filters to be odd (i.e, perfectly symmetrics)\r\n",
    "        if kernel_size%2==0:\r\n",
    "            self.kernel_size=self.kernel_size+1\r\n",
    "            \r\n",
    "        self.stride = stride\r\n",
    "        self.padding = padding\r\n",
    "        self.dilation = dilation\r\n",
    "\r\n",
    "        if bias:\r\n",
    "            raise ValueError('SincConv does not support bias.')\r\n",
    "        if groups > 1:\r\n",
    "            raise ValueError('SincConv does not support groups.')\r\n",
    "\r\n",
    "        self.sample_rate = sample_rate\r\n",
    "        self.min_low_hz = min_low_hz\r\n",
    "        self.min_band_hz = min_band_hz\r\n",
    "\r\n",
    "        # initialize filterbanks such that they are equally spaced in Mel scale\r\n",
    "        low_hz = 30\r\n",
    "        high_hz = self.sample_rate / 2 - (self.min_low_hz + self.min_band_hz)\r\n",
    "\r\n",
    "        mel = np.linspace(self.to_mel(low_hz),\r\n",
    "                          self.to_mel(high_hz),\r\n",
    "                          self.out_channels + 1)\r\n",
    "        hz = self.to_hz(mel)\r\n",
    "        \r\n",
    "\r\n",
    "        # filter lower frequency (out_channels, 1)\r\n",
    "        self.low_hz_ = nn.Parameter(torch.Tensor(hz[:-1]).view(-1, 1))\r\n",
    "\r\n",
    "        # filter frequency band (out_channels, 1)\r\n",
    "        self.band_hz_ = nn.Parameter(torch.Tensor(np.diff(hz)).view(-1, 1))\r\n",
    "\r\n",
    "        # Hamming window\r\n",
    "        #self.window_ = torch.hamming_window(self.kernel_size)\r\n",
    "        n_lin=torch.linspace(0, (self.kernel_size/2)-1, steps=int((self.kernel_size/2))) # computing only half of the window\r\n",
    "        self.window_=0.54-0.46*torch.cos(2*math.pi*n_lin/self.kernel_size);\r\n",
    "\r\n",
    "        # (1, kernel_size/2)\r\n",
    "        n = (self.kernel_size - 1) / 2.0\r\n",
    "        self.n_ = 2*math.pi*torch.arange(-n, 0).view(1, -1) / self.sample_rate # Due to symmetry, I only need half of the time axes\r\n",
    "\r\n",
    "    def forward(self, waveforms):\r\n",
    "        \"\"\"\r\n",
    "        Parameters\r\n",
    "        ----------\r\n",
    "        waveforms : `torch.Tensor` (batch_size, 1, n_samples)\r\n",
    "            Batch of waveforms.\r\n",
    "        Returns\r\n",
    "        -------\r\n",
    "        features : `torch.Tensor` (batch_size, out_channels, n_samples_out)\r\n",
    "            Batch of sinc filters activations.\r\n",
    "        \"\"\"\r\n",
    "\r\n",
    "        self.n_ = self.n_.to(waveforms.device)\r\n",
    "\r\n",
    "        self.window_ = self.window_.to(waveforms.device)\r\n",
    "\r\n",
    "        low = self.min_low_hz  + torch.abs(self.low_hz_)\r\n",
    "        \r\n",
    "        high = torch.clamp(low + self.min_band_hz + torch.abs(self.band_hz_),self.min_low_hz,self.sample_rate/2)\r\n",
    "        band=(high-low)[:,0]\r\n",
    "        \r\n",
    "        f_times_t_low = torch.matmul(low, self.n_)\r\n",
    "        f_times_t_high = torch.matmul(high, self.n_)\r\n",
    "\r\n",
    "        band_pass_left=((torch.sin(f_times_t_high)-torch.sin(f_times_t_low))/(self.n_/2))*self.window_ # Equivalent of Eq.4 of the reference paper (SPEAKER RECOGNITION FROM RAW WAVEFORM WITH SINCNET). I just have expanded the sinc and simplified the terms. This way I avoid several useless computations. \r\n",
    "        band_pass_center = 2*band.view(-1,1)\r\n",
    "        band_pass_right= torch.flip(band_pass_left,dims=[1])\r\n",
    "        \r\n",
    "        \r\n",
    "        band_pass=torch.cat([band_pass_left,band_pass_center,band_pass_right],dim=1)\r\n",
    "\r\n",
    "        \r\n",
    "        band_pass = band_pass / (2*band[:,None])\r\n",
    "        \r\n",
    "\r\n",
    "        self.filters = (band_pass).view(\r\n",
    "            self.out_channels, 1, self.kernel_size)\r\n",
    "\r\n",
    "        return F.conv1d(waveforms, self.filters, stride=self.stride,\r\n",
    "                        padding=self.padding, dilation=self.dilation,\r\n",
    "                         bias=None, groups=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "class RawNet2(nn.Module):\r\n",
    "    def __init__(self, d_args):\r\n",
    "        super(RawNet2, self).__init__()\r\n",
    "\r\n",
    "        self.ln = LayerNorm(d_args['nb_samp'])\r\n",
    "        self.first_conv = SincConv_fast(in_channels = d_args['in_channels'],\r\n",
    "            out_channels = d_args['filts'][0],\r\n",
    "            kernel_size = d_args['first_conv']\r\n",
    "            )\r\n",
    "        \r\n",
    "        self.first_bn = nn.BatchNorm1d(num_features = d_args['filts'][0])\r\n",
    "        self.lrelu = nn.LeakyReLU()\r\n",
    "        self.lrelu_keras = nn.LeakyReLU(negative_slope = 0.3)\r\n",
    "        \r\n",
    "        self.block0 = nn.Sequential(Residual_block_wFRM(nb_filts = d_args['filts'][1], first = True))\r\n",
    "        self.block1 = nn.Sequential(Residual_block_wFRM(nb_filts = d_args['filts'][1]))\r\n",
    " \r\n",
    "        self.block2 = nn.Sequential(Residual_block_wFRM(nb_filts = d_args['filts'][2]))\r\n",
    "        d_args['filts'][2][0] = d_args['filts'][2][1]\r\n",
    "        self.block3 = nn.Sequential(Residual_block_wFRM(nb_filts = d_args['filts'][2]))\r\n",
    "        self.block4 = nn.Sequential(Residual_block_wFRM(nb_filts = d_args['filts'][2]))\r\n",
    "        self.block5 = nn.Sequential(Residual_block_wFRM(nb_filts = d_args['filts'][2]))\r\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\r\n",
    "\r\n",
    "        self.bn_before_gru = nn.BatchNorm1d(num_features = d_args['filts'][2][-1])\r\n",
    "        self.gru = nn.GRU(input_size = d_args['filts'][2][-1],\r\n",
    "            hidden_size = d_args['gru_node'],\r\n",
    "            num_layers = d_args['nb_gru_layer'],\r\n",
    "            batch_first = True)\r\n",
    "\r\n",
    "        \r\n",
    "        self.fc1_gru = nn.Linear(in_features = d_args['gru_node'],\r\n",
    "            out_features = d_args['nb_fc_node'])\r\n",
    "        self.fc2_gru = nn.Linear(in_features = d_args['nb_fc_node'],\r\n",
    "            out_features = d_args['nb_classes'],\r\n",
    "            bias = True)\r\n",
    "        \r\n",
    "        self.sig = nn.Sigmoid()\r\n",
    "        \r\n",
    "    def forward(self, x, y = 0, is_test=False):\r\n",
    "        #follow sincNet recipe\r\n",
    "        nb_samp = x.shape[0]\r\n",
    "        len_seq = x.shape[1]\r\n",
    "\r\n",
    "        x = self.ln(x)\r\n",
    "        x=x.view(nb_samp,1,len_seq)\r\n",
    "        x = F.max_pool1d(torch.abs(self.first_conv(x)), 3)\r\n",
    "        x = self.first_bn(x)\r\n",
    "        x = self.lrelu_keras(x)\r\n",
    "        \r\n",
    "        x = self.block0(x)\r\n",
    "        x = self.block1(x)\r\n",
    "\r\n",
    "        x = self.block2(x)\r\n",
    "        x = self.block3(x)\r\n",
    "        x = self.block4(x)\r\n",
    "        x = self.block5(x)\r\n",
    "\r\n",
    "        x = self.bn_before_gru(x)\r\n",
    "        x = self.lrelu_keras(x)\r\n",
    "        x = x.permute(0, 2, 1)  #(batch, filt, time) >> (batch, time, filt)\r\n",
    "        self.gru.flatten_parameters()\r\n",
    "        x, _ = self.gru(x)\r\n",
    "        x = x[:,-1,:]\r\n",
    "        code = self.fc1_gru(x)\r\n",
    "        if is_test: return code\r\n",
    "        \r\n",
    "        code_norm = code.norm(p=2,dim=1, keepdim=True) / 10.\r\n",
    "        code = torch.div(code, code_norm)\r\n",
    "        out = self.fc2_gru(code)\r\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Loading RawNet with Large ASR Weights"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "import torch\r\n",
    "\r\n",
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "RAWNET2_LARGE_ASR_WEIGHTS_LOCATION = \"notebooks/TrainLargeAsrOnRawNet2/out/models/outmodel_epoch_14.pth\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "# Default value was 8, however NoteBook doesn't support >0\r\n",
    "NB_WORKER = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "model_dict = {}\r\n",
    "# We have used 2771 classes from the Large Asr to train RawNet model\r\n",
    "model_dict['nb_classes'] = 2764\r\n",
    "model_dict['first_conv'] = 251\r\n",
    "model_dict['in_channels'] = 1\r\n",
    "model_dict['filts'] = [128, [128,128], [128,128], [256,256]]\r\n",
    "model_dict['m_blocks'] = [2, 4]\r\n",
    "model_dict['nb_fc_att_node'] =[1]\r\n",
    "model_dict['nb_fc_node'] = 1024\r\n",
    "model_dict['gru_node'] = 1024\r\n",
    "model_dict['nb_gru_layer'] = 1\r\n",
    "model_dict['nb_samp'] = NUMBER_OF_SAMPLES\r\n",
    "\r\n",
    "model_dict['lr_decay'] = \"keras\"\r\n",
    "model_dict['do_lr_decay'] = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "model = RawNet2(model_dict)\r\n",
    "checkpoint = torch.load(RAWNET2_LARGE_ASR_WEIGHTS_LOCATION, map_location=torch.device(\"cpu\"))\r\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\r\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RawNet2(\n",
       "  (ln): LayerNorm()\n",
       "  (first_conv): SincConv_fast()\n",
       "  (first_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lrelu): LeakyReLU(negative_slope=0.01)\n",
       "  (lrelu_keras): LeakyReLU(negative_slope=0.3)\n",
       "  (block0): Sequential(\n",
       "    (0): Residual_block_wFRM(\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01)\n",
       "      (lrelu_keras): LeakyReLU(negative_slope=0.3)\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (mp): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (frm): FRM(\n",
       "        (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (sig): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (block1): Sequential(\n",
       "    (0): Residual_block_wFRM(\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01)\n",
       "      (lrelu_keras): LeakyReLU(negative_slope=0.3)\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (mp): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (frm): FRM(\n",
       "        (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (sig): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Residual_block_wFRM(\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01)\n",
       "      (lrelu_keras): LeakyReLU(negative_slope=0.3)\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (mp): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (frm): FRM(\n",
       "        (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (sig): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (block3): Sequential(\n",
       "    (0): Residual_block_wFRM(\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01)\n",
       "      (lrelu_keras): LeakyReLU(negative_slope=0.3)\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (mp): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (frm): FRM(\n",
       "        (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (sig): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (block4): Sequential(\n",
       "    (0): Residual_block_wFRM(\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01)\n",
       "      (lrelu_keras): LeakyReLU(negative_slope=0.3)\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (mp): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (frm): FRM(\n",
       "        (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (sig): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (block5): Sequential(\n",
       "    (0): Residual_block_wFRM(\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01)\n",
       "      (lrelu_keras): LeakyReLU(negative_slope=0.3)\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (mp): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (frm): FRM(\n",
       "        (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (sig): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (bn_before_gru): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (gru): GRU(128, 1024, batch_first=True)\n",
       "  (fc1_gru): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (fc2_gru): Linear(in_features=1024, out_features=2764, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "# Create DataLoader for Dataset\r\n",
    "\r\n",
    "timit_dataloader = data.DataLoader(timit_dataset,\r\n",
    "            batch_size = 1, \r\n",
    "            shuffle = False,\r\n",
    "            drop_last = False,\r\n",
    "            num_workers = NB_WORKER)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Extract Embeddings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "EMBEDDINGS_SAVE_FILE_LOCATION = \"notebooks/EvaluateTimitRawNetLargeAsr/out/embeddings.pkl\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "# Model must be in eval mode to extract embedding\r\n",
    "\r\n",
    "model.eval()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RawNet2(\n",
       "  (ln): LayerNorm()\n",
       "  (first_conv): SincConv_fast()\n",
       "  (first_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lrelu): LeakyReLU(negative_slope=0.01)\n",
       "  (lrelu_keras): LeakyReLU(negative_slope=0.3)\n",
       "  (block0): Sequential(\n",
       "    (0): Residual_block_wFRM(\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01)\n",
       "      (lrelu_keras): LeakyReLU(negative_slope=0.3)\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (mp): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (frm): FRM(\n",
       "        (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (sig): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (block1): Sequential(\n",
       "    (0): Residual_block_wFRM(\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01)\n",
       "      (lrelu_keras): LeakyReLU(negative_slope=0.3)\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (mp): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (frm): FRM(\n",
       "        (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (sig): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Residual_block_wFRM(\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01)\n",
       "      (lrelu_keras): LeakyReLU(negative_slope=0.3)\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (mp): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (frm): FRM(\n",
       "        (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (sig): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (block3): Sequential(\n",
       "    (0): Residual_block_wFRM(\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01)\n",
       "      (lrelu_keras): LeakyReLU(negative_slope=0.3)\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (mp): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (frm): FRM(\n",
       "        (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (sig): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (block4): Sequential(\n",
       "    (0): Residual_block_wFRM(\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01)\n",
       "      (lrelu_keras): LeakyReLU(negative_slope=0.3)\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (mp): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (frm): FRM(\n",
       "        (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (sig): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (block5): Sequential(\n",
       "    (0): Residual_block_wFRM(\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01)\n",
       "      (lrelu_keras): LeakyReLU(negative_slope=0.3)\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (mp): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (frm): FRM(\n",
       "        (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (sig): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (bn_before_gru): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (gru): GRU(128, 1024, batch_first=True)\n",
       "  (fc1_gru): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (fc2_gru): Linear(in_features=1024, out_features=2764, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "user_choice = input(\"Do You Want To Generate Embeddings? Type YES/NO\")\r\n",
    "\r\n",
    "if user_choice == \"YES\":\r\n",
    "    #Generating Embeddings\r\n",
    "    with torch.set_grad_enabled(False):\r\n",
    "        #1st, extract speaker embeddings.\r\n",
    "\r\n",
    "        # Each m_batch is a single wav\r\n",
    "        with open(EMBEDDINGS_SAVE_FILE_LOCATION, 'ab+') as fp:\r\n",
    "            for m_batch in tqdm(timit_dataloader, total=len(wav_path_list)):\r\n",
    "                l_code = []\r\n",
    "                for batch in m_batch[0]:\r\n",
    "                    batch = batch.to(device)\r\n",
    "                    code = model(x = batch, is_test=True)\r\n",
    "                    l_code.extend(code.cpu().numpy())\r\n",
    "                file_location = m_batch[2][0]\r\n",
    "                l_embedding = np.mean(l_code, axis=0)\r\n",
    "                pickle.dump((file_location, l_embedding), fp)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/1386 [00:00<?, ?it/s]C:\\Users\\molla\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "100%|██████████| 1386/1386 [00:12<00:00, 112.08it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "# Load from pickle\r\n",
    "# embeddings[path] = numpy_array\r\n",
    "\r\n",
    "embeddings = {}\r\n",
    "with open(EMBEDDINGS_SAVE_FILE_LOCATION, 'rb') as fr:\r\n",
    "    try:\r\n",
    "        while True:\r\n",
    "            data = pickle.load(fr)\r\n",
    "            embeddings[data[0]] = data[1]\r\n",
    "    except EOFError:\r\n",
    "        pass\r\n",
    "len(embeddings.keys())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1386"
      ]
     },
     "metadata": {},
     "execution_count": 130
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "embeddings[list(embeddings.keys())[0]]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 0.9363995 , -0.30366653,  0.52073425, ...,  1.2147985 ,\n",
       "       -0.82698315,  0.47207832], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "def speech_per_speaker(path_to_spk_dict):\r\n",
    "    # Returns a dictionary containing the number of utterrances for each speaker\r\n",
    "    speaker_ids = {}\r\n",
    "    for wav in path_to_spk_dict.keys():\r\n",
    "        spk_id = path_to_spk_dict[wav]\r\n",
    "        if spk_id in speaker_ids.keys():\r\n",
    "            speaker_ids[spk_id] += 1\r\n",
    "        else:\r\n",
    "            speaker_ids[spk_id] = 0\r\n",
    "\r\n",
    "    return speaker_ids"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "source": [
    "speech_per_spk = speech_per_speaker(path_to_spk_dict)\r\n",
    "total_number_of_speakers = len(speech_per_spk.keys())\r\n",
    "\r\n",
    "# This is the total number of speakers in this dataset\r\n",
    "total_number_of_speakers"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "462"
      ]
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Evaluate Timit RawNet2 Trained on Large Asr"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "source": [
    "from sklearn.metrics import roc_curve\r\n",
    "from scipy.optimize import brentq\r\n",
    "from scipy.interpolate import interp1d"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "source": [
    "# Specifies how many trials to make\r\n",
    "# In other words, how many times to calculate cos_sim to calculate EER\r\n",
    "NB_TRIALS = 10000\r\n",
    "\r\n",
    "# Where the validation trials should be saved\r\n",
    "VAL_TRIAL_LOCATION = \"notebooks/EvaluateTimitRawNetLargeAsr/SincNetDatasetSplits/val_trials.txt\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "source": [
    "def cos_sim(a,b):\r\n",
    "    return np.dot(a,b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "source": [
    "first_key = list(embeddings.keys())[0]\r\n",
    "second_key = list(embeddings.keys())[50]\r\n",
    "\r\n",
    "cos_sim(embeddings[first_key], embeddings[second_key])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.41225228"
      ]
     },
     "metadata": {},
     "execution_count": 161
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "source": [
    "def get_speaker_to_paths_dict(wav_path_list, path_to_spk_dict):\r\n",
    "    \r\n",
    "    spk_to_path_d = {}\r\n",
    "\r\n",
    "    for wav_path in wav_path_list:\r\n",
    "        spk_id = path_to_spk_dict[wav_path.lower()]\r\n",
    "\r\n",
    "        if spk_id in spk_to_path_d.keys():\r\n",
    "            spk_to_path_d[spk_id].append(wav_path)\r\n",
    "        else:\r\n",
    "            spk_to_path_d[spk_id] = [wav_path]\r\n",
    "    \r\n",
    "    return spk_to_path_d"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "source": [
    "spk_to_paths_d = get_speaker_to_paths_dict(wav_path_list, path_to_spk_dict)\r\n",
    "\r\n",
    "spk_to_paths_d[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['TRAIN/DR1/FDAW0/SI1271.WAV',\n",
       " 'TRAIN/DR1/FDAW0/SI1406.WAV',\n",
       " 'TRAIN/DR1/FDAW0/SI2036.WAV']"
      ]
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "# This function will generate a file that will contain which two files should be compared with cos similarities\r\n",
    "# Format:\r\n",
    "# 1 spk/_1_/audio/1.wav spk/_1_/audio/2.wav\r\n",
    "# 0 spk/_1_/audio/1.wav spk/_2_/audio/1.wav\r\n",
    "\r\n",
    "def generate_validation_trials(wav_path_list, nb_trial, val_trial_location, speaker_to_paths_d):\r\n",
    "    val_trial_file = open(val_trial_location, 'w')\r\n",
    "\r\n",
    "    # We define, same speaker trial as target trial\r\n",
    "    # Target trial: 1; Non-trg: 0\r\n",
    "\r\n",
    "    # There will be equal numbers of target and non target trials\r\n",
    "    nb_target_trials = int(nb_trial / 2)\r\n",
    "        \r\n",
    "    speakers_list = list(speaker_to_paths_d.keys())\r\n",
    "\r\n",
    "    #compose target trials\r\n",
    "    selected_spks = np.random.choice(speakers_list, size=nb_target_trials, replace=True)\r\n",
    "    for spk in selected_spks:\r\n",
    "        wav_paths_of_speaker = speaker_to_paths_d[spk]\r\n",
    "        utt_a, utt_b = np.random.choice(wav_paths_of_speaker, size=2, replace=False)\r\n",
    "        val_trial_file.write('1 %s %s\\n'%(utt_a, utt_b))\r\n",
    "\r\n",
    "    #compose non-target trials\r\n",
    "    for i in range(nb_target_trials):\r\n",
    "        two_different_speakers = np.random.choice(speakers_list, size=2, replace = False)\r\n",
    "        utt_a = np.random.choice(speaker_to_paths_d[two_different_speakers[0]], size=1)[0]\r\n",
    "        utt_b = np.random.choice(speaker_to_paths_d[two_different_speakers[1]], size=1)[0]\r\n",
    "        val_trial_file.write('0 %s %s\\n'%(utt_a, utt_b))\r\n",
    "\r\n",
    "    val_trial_file.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "source": [
    "generate_validation_trials(wav_path_list=wav_path_list, \r\n",
    "                            nb_trial=NB_TRIALS, \r\n",
    "                            val_trial_location=VAL_TRIAL_LOCATION, \r\n",
    "                            speaker_to_paths_d=spk_to_paths_d)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "source": [
    "# Retrieve validation trials from valtrial file\r\n",
    "def get_validation_trials(val_trial_location):\r\n",
    "    valtrials = []\r\n",
    "    with open(val_trial_location, \"r\") as file:\r\n",
    "        for line in file.readlines():\r\n",
    "            line = line.rstrip(\"\\n\")\r\n",
    "            splitted_line = line.split(\" \")\r\n",
    "\r\n",
    "            valtrials.append( (int(splitted_line[0]), splitted_line[1], splitted_line[2]) )\r\n",
    "\r\n",
    "    return valtrials"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "source": [
    "validation_trials = get_validation_trials(VAL_TRIAL_LOCATION)\r\n",
    "validation_trials[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 'TRAIN/DR5/MDAS0/SI1266.WAV', 'TRAIN/DR5/MDAS0/SI636.WAV')"
      ]
     },
     "metadata": {},
     "execution_count": 170
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "source": [
    "def get_y_true_and_score(validation_trials):\r\n",
    "    y_true = [vt[0] for vt in validation_trials]\r\n",
    "    y_score = []\r\n",
    "\r\n",
    "    for vt in validation_trials:\r\n",
    "        utt_1 = embeddings[vt[1]]\r\n",
    "        utt_2 = embeddings[vt[2]]\r\n",
    "        \r\n",
    "        score = cos_sim(utt_1, utt_2)\r\n",
    "        y_score.append(score)\r\n",
    "\r\n",
    "    return y_true, y_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "source": [
    "y_true, y_score = get_y_true_and_score(validation_trials)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### EER Score"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "source": [
    "def calculate_eer(y_true, y_score):\r\n",
    "    fpr, tpr, _  = roc_curve(y_true=y_true, y_score=y_score, pos_label=1)\r\n",
    "    eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\r\n",
    "    return eer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "source": [
    "eer = calculate_eer(y_true, y_score)\r\n",
    "eer"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.1779999999990866"
      ]
     },
     "metadata": {},
     "execution_count": 174
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "source": [
    "# Graph NB_SAMPLE / eer graph\r\n",
    "\r\n",
    "eers = []\r\n",
    "nb_trials = [i for i in range(500, 20000, 500)]\r\n",
    "\r\n",
    "for nb_trial in nb_trials:\r\n",
    "    print(\"Number of trials:\", nb_trial, end=\" \")\r\n",
    "    generate_validation_trials(wav_path_list=wav_path_list, \r\n",
    "                            nb_trial=nb_trial, \r\n",
    "                            val_trial_location=VAL_TRIAL_LOCATION, \r\n",
    "                            speaker_to_paths_d=spk_to_paths_d)\r\n",
    "\r\n",
    "    validation_trials = get_validation_trials(VAL_TRIAL_LOCATION)\r\n",
    "\r\n",
    "    y_true, y_score = get_y_true_and_score(validation_trials)\r\n",
    "\r\n",
    "    eer = calculate_eer(y_true, y_score)\r\n",
    "    eers.append(eer)\r\n",
    "    print(\"EER:\", eer)\r\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of trials: 500 EER: 0.15300000000000022\n",
      "Number of trials: 1000 EER: 0.16800000000060783\n",
      "Number of trials: 1500 EER: 0.14933333333154802\n",
      "Number of trials: 2000 EER: 0.1512000000000106\n",
      "Number of trials: 2500 EER: 0.18720000000000003\n",
      "Number of trials: 3000 EER: 0.16466666666800336\n",
      "Number of trials: 3500 EER: 0.1685714285714287\n",
      "Number of trials: 4000 EER: 0.17749999999895993\n",
      "Number of trials: 4500 EER: 0.1640000000001028\n",
      "Number of trials: 5000 EER: 0.16679999999999998\n",
      "Number of trials: 5500 EER: 0.17309090909184432\n",
      "Number of trials: 6000 EER: 0.16333333333445532\n",
      "Number of trials: 6500 EER: 0.1652307692306763\n",
      "Number of trials: 7000 EER: 0.16735064935064914\n",
      "Number of trials: 7500 EER: 0.1688\n",
      "Number of trials: 8000 EER: 0.16900000000074555\n",
      "Number of trials: 8500 EER: 0.16870588235293943\n",
      "Number of trials: 9000 EER: 0.17367676767676776\n",
      "Number of trials: 9500 EER: 0.16568421052632\n",
      "Number of trials: 10000 EER: 0.1650285714285714\n",
      "Number of trials: 10500 EER: 0.167047619047124\n",
      "Number of trials: 11000 EER: 0.16945454545454544\n",
      "Number of trials: 11500 EER: 0.16921739130569585\n",
      "Number of trials: 12000 EER: 0.17283333333344061\n",
      "Number of trials: 12500 EER: 0.17034181818181818\n",
      "Number of trials: 13000 EER: 0.1641538461532898\n",
      "Number of trials: 13500 EER: 0.17259259259259258\n",
      "Number of trials: 14000 EER: 0.16885714285598896\n",
      "Number of trials: 14500 EER: 0.17241379310282282\n",
      "Number of trials: 15000 EER: 0.17115555555582096\n",
      "Number of trials: 15500 EER: 0.17161290322603218\n",
      "Number of trials: 16000 EER: 0.17587499999998524\n",
      "Number of trials: 16500 EER: 0.16812121212150893\n",
      "Number of trials: 17000 EER: 0.16970588235277348\n",
      "Number of trials: 17500 EER: 0.1714285714285368\n",
      "Number of trials: 18000 EER: 0.16899999999999984\n",
      "Number of trials: 18500 EER: 0.1658441971383148\n",
      "Number of trials: 19000 EER: 0.17368421052631577\n",
      "Number of trials: 19500 EER: 0.17192156862745098\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "from pylab import text\r\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "source": [
    "plt.plot(nb_trials, eers)\r\n",
    "axes = plt.gca()\r\n",
    "axes.set_xlabel(\"Numbers of Trials\")\r\n",
    "axes.set_ylabel(\"EER\")\r\n",
    "axes.set_ylim(0,1.0)\r\n",
    "\r\n",
    "print(\"Average EER:\", sum(eers)/len(eers))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average EER: 0.16834445396327405\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('pytorch': conda)"
  },
  "interpreter": {
   "hash": "83fea67622c0fa859a960c0bf8a89199ff21c56f3cdd300f29516e12427a6ea7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
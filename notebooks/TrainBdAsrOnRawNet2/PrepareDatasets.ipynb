{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Preparing BANGLA ASR DATASET\r\n",
    "\r\n",
    "This notebook will make the regulations for splitting the entire dataset into train, validation and test sets. It will create text files containing the stems (file names) of the wavs in each different set.\r\n",
    "\r\n",
    "[[[ If the DatasetPreparations folder already contains the 6 output files, then it is not necessary to run this notebook. ]]]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Terminologies:\r\n",
    "\r\n",
    "* Stem: Stem is the file name from a path. For example, the stem of \"a/b/c/abc.wav\" is \"abc\"\r\n",
    "* devset: Devset indicates the set of files that will be used during development or training. This includes both train set and evaluation set."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Necessary imports:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import glob\r\n",
    "import csv\r\n",
    "\r\n",
    "from pathlib import Path\r\n",
    "\r\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Directories are assumed to have a trailing '/' or '\\\\' in all the subsequent code\r\n",
    "\r\n",
    "CURRENT_WORKING_DIRECTORY = \"W:/SpeakerRecognitionResearch\"\r\n",
    "\r\n",
    "BANGLA_ASR_DATASET_DIRECTORY = \"data/BanglaASR/WavFiles/\"\r\n",
    "BANGLA_ASR_TSV_LOCATION = \"data/BanglaASR/utt_spk_text.tsv\"\r\n",
    "\r\n",
    "# To avoid file location related errors, we make sure \"SpeakerRecognitionResearch\" root folder is the current working directory.\r\n",
    "os.chdir(CURRENT_WORKING_DIRECTORY)\r\n",
    "os.getcwd()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'W:\\\\SpeakerRecognitionResearch'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Output files:\r\n",
    "\r\n",
    "The following output files will be generated by this notebook:\r\n",
    "1. trainset_list.txt: List of all stems that will be used for training\r\n",
    "2. evalset_list.txt: List of all stems that will be used for evaluation in the training loop\r\n",
    "3. test_set.txt: List of all stems that will be used for testing/validating after training phase is complete\r\n",
    "4. devset_class_order.txt: Order of the classes used for both trainset and evalset\r\n",
    "5. testset_class_order.txt: Order of the classes used for testset\r\n",
    "6. eval_trials.txt: (expected utt1 utt2) tuples for each trial to compute for evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "TRAINSET_LIST_LOCATION = \"notebooks/TrainBdAsrOnRawNet2/DatasetPreparations/trainset_list.txt\"\r\n",
    "EVALSET_LIST_LOCATION = \"notebooks/TrainBdAsrOnRawNet2/DatasetPreparations/evalset_list.txt\"\r\n",
    "TESTSET_LIST_LOCATION = \"notebooks/TrainBdAsrOnRawNet2/DatasetPreparations/testset_list.txt\"\r\n",
    "DEVSET_CLASS_ORDER_LOCATION = \"notebooks/TrainBdAsrOnRawNet2/DatasetPreparations/devset_classes.txt\"\r\n",
    "TESTSET_CLASS_ORDER_LOCATION = \"notebooks/TrainBdAsrOnRawNet2/DatasetPreparations/testset_classes.txt\"\r\n",
    "\r\n",
    "EVAL_TRIALS_LOCATION = \"notebooks/TrainBdAsrOnRawNet2/DatasetPreparations/eval_trials.txt\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# There are in total 508 speakers in the dataset\r\n",
    "TEST_CLASS_NUMBERS = 100\r\n",
    "DEV_CLASS_NUMBERS = 408\r\n",
    "\r\n",
    "EVAL_TRAIN_RATIO = 0.10\r\n",
    "\r\n",
    "# Don't change it, to keep the work reproducible\r\n",
    "RANDOM_SEED = 99"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def get_wav_list(dataset_dir):\r\n",
    "    # Given a directory, return path list of all wav files\r\n",
    "    pattern = '**/*.wav'\r\n",
    "    files = glob.glob(dataset_dir + pattern , recursive=True)\r\n",
    "\r\n",
    "    # Normalize the file paths. To get file paths with '/' or '\\\\' consistently depending on OS\r\n",
    "    wav_list = [os.path.normpath(i) for i in files]\r\n",
    "    return wav_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "wav_paths_list = get_wav_list(BANGLA_ASR_DATASET_DIRECTORY)\r\n",
    "len(wav_paths_list)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "218703"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Label dictionaries\r\n",
    "\r\n",
    "Three dictionaries will be helpful to us\r\n",
    "\r\n",
    "1. stem_to_speaker_dict: Given stem, who is it's speaker?\r\n",
    "2. speaker_to_paths_dict: Given a speaker, what are their audio paths?\r\n",
    "3. stem_to_path_dict: Given the stem, what is its path?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def get_stem_to_speaker_dict(tsv_loc):\r\n",
    "    # Reads the annotation tsv file provided with the dataset \r\n",
    "    # and returns a stem to speaker mapping dictionary\r\n",
    "    stem_to_speaker_d = {}\r\n",
    "\r\n",
    "    with open(tsv_loc, encoding=\"utf-8\") as tsvfile:\r\n",
    "        tsvreader = csv.reader(tsvfile, delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\r\n",
    "        for line in tsvreader:\r\n",
    "            wav_file_name = line[0]\r\n",
    "            speaker_id = line[1]\r\n",
    "\r\n",
    "            stem_to_speaker_d[wav_file_name] = speaker_id\r\n",
    "\r\n",
    "    return stem_to_speaker_d"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "stem_to_speaker_dict = get_stem_to_speaker_dict(BANGLA_ASR_TSV_LOCATION)\r\n",
    "print(\"Size:\", len(stem_to_speaker_dict), \"Speaker of 000020a912:\", stem_to_speaker_dict[\"000020a912\"])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Size: 218703 Speaker of 000020a912: 16cfb\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def get_speaker_to_paths_dict(wav_list, stem_to_speaker_dict):\r\n",
    "    \r\n",
    "    spk_to_path_d = {}\r\n",
    "\r\n",
    "    for wav_path in wav_list:\r\n",
    "        wav_name = Path(wav_path).stem\r\n",
    "        spk_id = stem_to_speaker_dict[wav_name]\r\n",
    "\r\n",
    "        if spk_id in spk_to_path_d.keys():\r\n",
    "            spk_to_path_d[spk_id].append(wav_path)\r\n",
    "        else:\r\n",
    "            spk_to_path_d[spk_id] = [wav_path]\r\n",
    "    \r\n",
    "    return spk_to_path_d"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "speaker_to_paths_dict = get_speaker_to_paths_dict(wav_paths_list, stem_to_speaker_dict)\r\n",
    "len(speaker_to_paths_dict.keys())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "508"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "total = 0\r\n",
    "for key in speaker_to_paths_dict.keys():\r\n",
    "    total += len(speaker_to_paths_dict[key])\r\n",
    "\r\n",
    "total"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "218703"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def get_stem_to_path_dict(stem_list, wav_paths_list):\r\n",
    "    # Sets are faster to search\r\n",
    "    stem_set = set(stem_list)\r\n",
    "    \r\n",
    "    stem_to_path_d ={}\r\n",
    "    for wav_path in wav_paths_list:\r\n",
    "        wav_stem = Path(wav_path).stem\r\n",
    "        if wav_stem in stem_set:\r\n",
    "            if wav_stem in stem_to_path_d:\r\n",
    "                stem_to_path_d[wav_stem].append(wav_path)\r\n",
    "            else:\r\n",
    "                stem_to_path_d[wav_stem] = [wav_path]\r\n",
    "\r\n",
    "    return stem_to_path_d          \r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "stem_list = stem_to_speaker_dict.keys()\r\n",
    "\r\n",
    "stem_to_path_dict = get_stem_to_path_dict(stem_list, wav_paths_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "stem_to_path_dict['c47c6e6be0']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['data\\\\BanglaASR\\\\WavFiles\\\\asr_bengali_c\\\\asr_bengali\\\\data\\\\c4\\\\c47c6e6be0.wav']"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split whole dataset into dev and test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "random.seed(RANDOM_SEED)\r\n",
    "test_speakers_keys = random.sample(speaker_to_paths_dict.keys(), TEST_CLASS_NUMBERS)\r\n",
    "random.seed(RANDOM_SEED)\r\n",
    "\r\n",
    "len(test_speakers_keys)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "test_speakers_wavs_stems = []\r\n",
    "dev_speakers_wavs_stems = []\r\n",
    "\r\n",
    "total = 0\r\n",
    "\r\n",
    "for key in speaker_to_paths_dict.keys():\r\n",
    "    current_speaker_wavs = speaker_to_paths_dict[key]\r\n",
    "    current_speaker_wavs_stems = [Path(x).stem for x in current_speaker_wavs]\r\n",
    "    total += len(current_speaker_wavs_stems)\r\n",
    "\r\n",
    "    if key in test_speakers_keys:\r\n",
    "        test_speakers_wavs_stems += current_speaker_wavs_stems\r\n",
    "    else:\r\n",
    "        dev_speakers_wavs_stems += current_speaker_wavs_stems\r\n",
    "    \r\n",
    "print(total)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "218703\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "print(len(test_speakers_wavs_stems), len(dev_speakers_wavs_stems))\r\n",
    "print(len(test_speakers_wavs_stems) + len(dev_speakers_wavs_stems))\r\n",
    "\r\n",
    "# 42075 176628\r\n",
    "# 218703"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "42075 176628\n",
      "218703\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have divided dataset into dev and test.\r\n",
    "Now, we need to divide dev between train and eval"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "total_dev_wavs = len(dev_speakers_wavs_stems)\r\n",
    "num_eval_wavs = int(total_dev_wavs * EVAL_TRAIN_RATIO)\r\n",
    "\r\n",
    "random.seed(RANDOM_SEED)\r\n",
    "random.shuffle(dev_speakers_wavs_stems)\r\n",
    "random.seed(RANDOM_SEED)\r\n",
    "\r\n",
    "eval_stems, train_stems = dev_speakers_wavs_stems[:num_eval_wavs], dev_speakers_wavs_stems[num_eval_wavs:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "train_size = len(train_stems)\r\n",
    "eval_size = len(eval_stems)\r\n",
    "test_size = len(test_speakers_wavs_stems)\r\n",
    "\r\n",
    "print(\"Train size:\", train_size)\r\n",
    "print(\"Eval size:\", eval_size)\r\n",
    "print(\"Test size:\", test_size)\r\n",
    "\r\n",
    "print(\"Total:\", train_size+eval_size+test_size)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train size: 158966\n",
      "Eval size: 17662\n",
      "Test size: 42075\n",
      "Total: 218703\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Writing to the output files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "with open(TRAINSET_LIST_LOCATION, \"w\") as file:\r\n",
    "    for stem in train_stems:\r\n",
    "        file.write(stem+\"\\n\")\r\n",
    "\r\n",
    "with open(EVALSET_LIST_LOCATION, \"w\") as file:\r\n",
    "    for stem in eval_stems:\r\n",
    "        file.write(stem+\"\\n\")\r\n",
    "\r\n",
    "with open(TESTSET_LIST_LOCATION, \"w\") as file:\r\n",
    "    for stem in test_speakers_wavs_stems:\r\n",
    "        file.write(stem+\"\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Set for uniqueness\r\n",
    "# Sorted list for consistency in the order\r\n",
    "# \r\n",
    "dev_speakers_list = sorted(list(set([stem_to_speaker_dict[stem] for stem in dev_speakers_wavs_stems])))\r\n",
    "test_speakers_list = sorted(list(set([stem_to_speaker_dict[stem] for stem in test_speakers_wavs_stems])))\r\n",
    "len(dev_speakers_list)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "with open(DEVSET_CLASS_ORDER_LOCATION, \"w\") as file:\r\n",
    "    for speaker in dev_speakers_list:\r\n",
    "        file.write(speaker+\"\\n\")\r\n",
    "\r\n",
    "with open(TESTSET_CLASS_ORDER_LOCATION, \"w\") as file:\r\n",
    "    for speaker in test_speakers_list:\r\n",
    "        file.write(speaker+\"\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation Trials"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "NUM_TRIALS = 10000"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# This function will generate a file that will contain which two files should be compared with cos similarities\r\n",
    "# Format:\r\n",
    "# 1 spk/_1_/audio/1.wav spk/_1_/audio/2.wav\r\n",
    "# 0 spk/_1_/audio/1.wav spk/_2_/audio/1.wav\r\n",
    "\r\n",
    "def generate_validation_trials(wav_list, nb_trial, val_trial_location, speaker_to_paths_d):\r\n",
    "    val_trial_file = open(val_trial_location, 'w')\r\n",
    "\r\n",
    "    # We define, same speaker trial as target trial\r\n",
    "    # Target trial: 1; Non-trg: 0\r\n",
    "\r\n",
    "    # There will be equal numbers of target and non target trials\r\n",
    "    nb_target_trials = int(nb_trial / 2)\r\n",
    "        \r\n",
    "    speakers_list = list(speaker_to_paths_d.keys())\r\n",
    "\r\n",
    "    #compose target trials\r\n",
    "    selected_spks = np.random.choice(speakers_list, size=nb_target_trials, replace=True)\r\n",
    "    for spk in selected_spks:\r\n",
    "        wav_paths_of_speaker = speaker_to_paths_d[spk]\r\n",
    "        utt_a, utt_b = np.random.choice(wav_paths_of_speaker, size=2, replace=False)\r\n",
    "        utt_a_stem, utt_b_stem = Path(utt_a).stem, Path(utt_b).stem\r\n",
    "        val_trial_file.write('1 %s %s\\n'%(utt_a_stem, utt_b_stem))\r\n",
    "\r\n",
    "    #compose non-target trials\r\n",
    "    for i in range(nb_target_trials):\r\n",
    "        two_different_speakers = np.random.choice(speakers_list, size=2, replace = False)\r\n",
    "        utt_a = np.random.choice(speaker_to_paths_d[two_different_speakers[0]], size=1)[0]\r\n",
    "        utt_b = np.random.choice(speaker_to_paths_d[two_different_speakers[1]], size=1)[0]\r\n",
    "        utt_a_stem, utt_b_stem = Path(utt_a).stem, Path(utt_b).stem\r\n",
    "        val_trial_file.write('0 %s %s\\n'%(utt_a_stem, utt_b_stem))\r\n",
    "\r\n",
    "    val_trial_file.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "eval_speakers_to_path_dict = {}\r\n",
    "\r\n",
    "eval_stem_set = set(eval_stems)\r\n",
    "\r\n",
    "for speaker in speaker_to_paths_dict.keys():\r\n",
    "    for path in speaker_to_paths_dict[speaker]:\r\n",
    "        if Path(path).stem in eval_stem_set:\r\n",
    "            if speaker in eval_speakers_to_path_dict.keys():\r\n",
    "                eval_speakers_to_path_dict[speaker].append(path)\r\n",
    "            else:\r\n",
    "                eval_speakers_to_path_dict[speaker] = [path]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "total = 0\r\n",
    "for speaker in eval_speakers_to_path_dict:\r\n",
    "    total += len(eval_speakers_to_path_dict[speaker])\r\n",
    "\r\n",
    "total"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "17662"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "eval_paths = []\r\n",
    "for stem in eval_stems:\r\n",
    "    eval_paths.append(stem_to_path_dict[stem])\r\n",
    "len(eval_paths)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "17662"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "generate_validation_trials(eval_paths, NUM_TRIALS, EVAL_TRIALS_LOCATION, eval_speakers_to_path_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('pytorch': conda)"
  },
  "interpreter": {
   "hash": "83fea67622c0fa859a960c0bf8a89199ff21c56f3cdd300f29516e12427a6ea7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
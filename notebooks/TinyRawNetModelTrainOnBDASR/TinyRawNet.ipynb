{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TinyRawNet: A Student of RawNet Speaker Recognition Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Necessary Imports:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "import torch\r\n",
    "from torch.utils import data\r\n",
    "\r\n",
    "import csv\r\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "class TA_Dataset_VoxCeleb2(data.Dataset):\r\n",
    "\tdef __init__(self, list_IDs, base_dir, nb_samp = 0, window_size = 0, labels = {}, cut = True, return_label = True, norm_scale = True):\r\n",
    "\t\t'''\r\n",
    "\t\tself.list_IDs\t: list of strings (each string: utt key)\r\n",
    "\t\tself.labels\t\t: dictionary (key: utt key, value: label integer)\r\n",
    "\t\tself.nb_samp\t: integer, the number of timesteps for each mini-batch\r\n",
    "\t\tcut\t\t\t\t: (boolean) adjust utterance duration for mini-batch construction\r\n",
    "\t\treturn_label\t: (boolean) \r\n",
    "\t\tnorm_scale\t\t: (boolean) normalize scale alike SincNet github repo\r\n",
    "\t\t'''\r\n",
    "\t\tself.list_IDs = list_IDs\r\n",
    "\t\tself.window_size = window_size\r\n",
    "\t\tself.nb_samp = nb_samp\r\n",
    "\t\tself.base_dir = base_dir\r\n",
    "\t\tself.labels = labels\r\n",
    "\t\tself.cut = cut\r\n",
    "\t\tself.return_label = return_label\r\n",
    "\t\tself.norm_scale = norm_scale\r\n",
    "\t\tif self.cut and self.nb_samp == 0: raise ValueError('when adjusting utterance length, \"nb_samp\" should be input')\r\n",
    "\r\n",
    "\tdef __len__(self):\r\n",
    "\t\treturn len(self.list_IDs)\r\n",
    "\r\n",
    "\tdef __getitem__(self, index):\r\n",
    "\t\tID = self.list_IDs[index]\r\n",
    "\t\ttry:\r\n",
    "\t\t\tX, _ = sf.read(self.base_dir+ID) \r\n",
    "\t\t\tX = X.astype(np.float64)\r\n",
    "\t\texcept:\r\n",
    "\t\t\traise ValueError('%s'%ID)\r\n",
    "\r\n",
    "\t\tif self.norm_scale:\r\n",
    "\t\t\tX = self._normalize_scale(X).astype(np.float32)\r\n",
    "\t\tX = X.reshape(1,-1)\r\n",
    "\r\n",
    "\t\tlist_X = []\r\n",
    "\t\tnb_time = X.shape[1]\r\n",
    "\t\tif nb_time < self.nb_samp:\r\n",
    "\t\t\tnb_dup = int(self.nb_samp / nb_time) + 1\r\n",
    "\t\t\tlist_X.append(np.tile(X, (1, nb_dup))[:, :self.nb_samp][0])\r\n",
    "\t\telif nb_time > self.nb_samp:\r\n",
    "\t\t\tstep = self.nb_samp - self.window_size\r\n",
    "\t\t\titeration = int( (nb_time - self.window_size) / step ) + 1\r\n",
    "\t\t\tfor i in range(iteration):\r\n",
    "\t\t\t\tif i == 0:\r\n",
    "\t\t\t\t\tlist_X.append(X[:, :self.nb_samp][0])\r\n",
    "\t\t\t\telif i < iteration - 1:\r\n",
    "\t\t\t\t\tlist_X.append(X[:, i*step : i*step + self.nb_samp][0])\r\n",
    "\t\t\t\telse:\r\n",
    "\t\t\t\t\tlist_X.append(X[:, -self.nb_samp:][0])\r\n",
    "\t\telse :\r\n",
    "\t\t\tlist_X.append(X[0])\r\n",
    "\r\n",
    "\t\tif not self.return_label:\r\n",
    "\t\t\treturn list_X\r\n",
    "\t\ty = self.labels[ID.split('/')[0]]\r\n",
    "\t\treturn list_X, y \r\n",
    "\r\n",
    "\tdef _normalize_scale(self, x):\r\n",
    "\t\t'''\r\n",
    "\t\tNormalize sample scale alike SincNet.\r\n",
    "\t\t'''\r\n",
    "\t\treturn x/np.max(np.abs(x))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Constants:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Directories are assumed to have a trailing '/' or '\\\\' in all the subsequent code\r\n",
    "\r\n",
    "CURRENT_WORKING_DIRECTORY = \"W:/SpeakerRecognitionResearch\"\r\n",
    "\r\n",
    "BANGLA_ASR_DATASET_DIRECTORY = \"data/BanglaASR/WavFiles/\"\r\n",
    "BANGLA_ASR_TSV_LOCATION = \"data/BanglaASR/utt_spk_text.tsv\"\r\n",
    "\r\n",
    "# To avoid file location related errors, we make sure \"SpeakerRecognitionResearch\" root folder is the current working directory.\r\n",
    "os.chdir(CURRENT_WORKING_DIRECTORY)\r\n",
    "os.getcwd()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'W:\\\\SpeakerRecognitionResearch'"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom dataset for Bangla ASR"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "class BanglaAsrDataset(data.Dataset):\r\n",
    "    def __init__(self, dataset_dir, tsv_loc):\r\n",
    "\r\n",
    "        tsv_dataframe = pd.read_csv(tsv_loc, quoting=csv.QUOTE_NONE, sep='\\t', header=None)\r\n",
    "\r\n",
    "        # The TSV file contains speech annotations in the third column.\r\n",
    "        # We don't need the annotations, so we drop the column\r\n",
    "        tsv_dataframe = tsv_dataframe.iloc[:,:-1]\r\n",
    "\r\n",
    "        self.wav_to_spk_mapping = dict(sorted(tsv_dataframe.values.tolist()))\r\n",
    "        self.dataset_dir = dataset_dir\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        pass\r\n",
    "\r\n",
    "    def __getitem__(self, index):\r\n",
    "        pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "bangla_asr_dataset = BanglaAsrDataset(\r\n",
    "    dataset_dir=BANGLA_ASR_DATASET_DIR,\r\n",
    "    tsv_loc = BANGLA_ASR_TSV_LOC\r\n",
    ")\r\n",
    "\r\n",
    "assert bangla_asr_dataset.wav_to_spk_mapping['000020a912'] == '16cfb' , \"The dictionary returned wrong mapping\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('pytorch': conda)"
  },
  "interpreter": {
   "hash": "83fea67622c0fa859a960c0bf8a89199ff21c56f3cdd300f29516e12427a6ea7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}